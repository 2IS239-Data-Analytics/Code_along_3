{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Scale, Standardize, or Normalize with scikit-learn.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2IS239-Data-Analytics/Code_along_2/blob/main/Scale%2C_Standardize%2C_or_Normalize_with_scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "53c90f720c67f85516c2e9350017d9da94185435",
        "id": "OMmidMqSn5NE"
      },
      "source": [
        "# Tutorial Scale, Standardize, or Normalize with scikit-learn\n",
        "### När ska man använda MinMaxScaler, RobustScaler, StandardScaler, och Normalizer\n",
        "### Attribution: Jeff Hale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8174f53e7350d7f282636b7d5a94d8299c554552",
        "id": "5q3GxMHen5NS"
      },
      "source": [
        "### Varför är det ofta nödvändigt att genomföra så kallad variable transformation/feature scaling det vill säga, standardisera, normalisera eller på andra sätt ändra skalan på data vid dataaalys?\n",
        "\n",
        "Som jag gått igenom på föreläsning 3 kan data behöva formateras (variable transformation) för att förbättra prestandan hos många algoritmer för dataanalys. En typ av formatering av data, som går att göra på många olika sätt, är så kallad skalning av attribut (feature scaling). Det kan finnas flera anledningar till att data kan behöv skalas, några exempel är:\n",
        "\n",
        "* Exempelvis neurala nätverk, regressionsalgoritmer och K-nearest neighbors fungerar inte lika bra om inte de attribut (features) som algoritmen använder befinner sig i relativt lika skalor. \n",
        "\n",
        "* Vissa av metoderna för att skala, standardisera och normalisera kan också minska den negativa påverkan outliers kan ha i vissa algoritmer.\n",
        "\n",
        "* Ibland är det också av vikt att ha data som är normalfördelat (standardiserat) \n",
        "\n",
        "*Med skala menas inte den skala som hänsyftas på exempelvis kartor där det brukar anges att skalan är 1:50 000 vilket tolkas som att varje avstånd på kartan är 50 000 ggr kortare än i verkligheten.* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "9pMsVPKZn5NS"
      },
      "source": [
        "#Importerar de bibliotek vi behöver\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn import preprocessing\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "#Denna kod sätter upp hur matplotlib ska visa grafer och plotar\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "#Generera lite input \n",
        "#(den som är extremt intresserad kan läsa följande, intressanta och roliga förklaring kring varför random.seed egentligen är pseudorandom)\n",
        "#https://www.sharpsightlabs.com/blog/numpy-random-seed/\n",
        "np.random.seed(34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2ba6eda07c92b9f8a5dfaaf035359243bc977ded",
        "id": "likLwamMn5NT"
      },
      "source": [
        "# Original Distributions \n",
        "\n",
        "Data som det kan se ut i original, alltså när det samlats in, innan någon pre-processing har genomförts.\n",
        "\n",
        "För att ha data att använda i övningarna skapar nedanstående kod ett antal randomiserade spridningar av data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "50cda9065e05259061321479ab04ed469ce26de4",
        "id": "n9WywBlHn5NT"
      },
      "source": [
        "#skapa kolumner med olika fördelningar \n",
        "df = pd.DataFrame({ \n",
        "    'beta': np.random.beta(5, 1, 1000) * 60,        # beta\n",
        "    'exponential': np.random.exponential(10, 1000), # exponential\n",
        "    'normal_p': np.random.normal(10, 2, 1000),      # normal platykurtic\n",
        "    'normal_l': np.random.normal(10, 10, 1000),     # normal leptokurtic\n",
        "})\n",
        "\n",
        "# make bimodal distribution\n",
        "first_half = np.random.normal(20, 3, 500) \n",
        "second_half = np.random.normal(-20, 3, 500) \n",
        "bimodal = np.concatenate([first_half, second_half])\n",
        "\n",
        "df['bimodal'] = bimodal\n",
        "\n",
        "# create list of column names to use later\n",
        "col_names = list(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1acea8ada274cab28babd79959f92431acd90fb9",
        "id": "w4vvl-Zwn5NU"
      },
      "source": [
        "## Uppgift 1: \n",
        "\n",
        "a. Plotta de kurvor som skapats i ovanstående cell i en och samma koordinatsystem med hjälp av [seaborn biblioteket](https://seaborn.pydata.org/api.html#distribution-api).\n",
        "\n",
        ">Se till att det är tydligt vilken kurva som representerar vilken distribution.\n",
        ">\n",
        ">Koden för själva koordinatsystemet är given, fortsätt koda i samma cell\n",
        ">\n",
        ">HINT! alla fem är distribution plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "06c4730029c407202b169c31e92fb247d824de56",
        "id": "5qhnAI7un5NU"
      },
      "source": [
        "# plot original distribution plot\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
        "ax1.set_title('Original Distributions')\n",
        "\n",
        "#De fem kurvorna\n",
        "sns.kdeplot(df['beta'], ax=ax1)\n",
        "sns.kdeplot(df['exponential'], ax=ax1)\n",
        "sns.kdeplot(df['normal_p'], ax=ax1)\n",
        "sns.kdeplot(df['normal_l'], ax=ax1)\n",
        "sns.kdeplot(df['bimodal'], ax=ax1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgtZoqNIn5NV"
      },
      "source": [
        "b. Visa de fem första raderna i den dataframe som innehåller alla distributioner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ed5da4af29ae63b90b0dc0fcfc62ad857a0be11b",
        "id": "_qTKeI3rn5NV"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8002769d4872942a779e8ad219fa8dafaa111d9d",
        "id": "RCJOlRpHn5NW"
      },
      "source": [
        "c. För samtliga fem attribut, beräkna:\n",
        "\n",
        "* medel\n",
        "* median\n",
        "\n",
        "Vad för bra metod kan användas för att få ett antal statistiska mått på en dataframe? Hämta denna information med denna metod."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6HbZHcJn5NW"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UJBmc45n5NW"
      },
      "source": [
        "df.skew()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGG9ZNQwn5NX"
      },
      "source": [
        "d. I pandas kan du plotta din dataframe på några olika sätt. Gör en plot för att ta reda på hur skalan på de olika attibuten ser ut, befinner sig alla fem i ungefär samma skala?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgYnlqV9n5NX"
      },
      "source": [
        "df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "50a2f43eeabf0557ddca3c1691d3bdacc21cf98a",
        "id": "RoSDM2Nkn5NX"
      },
      "source": [
        "* Samtliga värden ligger inom liknande intervall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2b8cc2f3a9578552eff85d01f09bbf95701bba38",
        "id": "Js4XLQMbn5NX"
      },
      "source": [
        "e. Vad händer om följande kolumn med randomiserade värden läggs till?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bb6355d0905daf893f2854f5ae86773f74b0c25c",
        "id": "wEqWm4oBn5NY"
      },
      "source": [
        "new_column = np.random.normal(1000000, 10000, (1000,1))\n",
        "df['new_column'] = new_column\n",
        "col_names.append('new_column')\n",
        "df['new_column'].plot(kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "43f8cce6dbb0fcb30c7d54b7a01852fa3d6af178",
        "id": "8M9YUdeXn5NY"
      },
      "source": [
        "# plot våra originalvärden tillsammans med det nya värdet\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
        "ax1.set_title('Original Distributions')\n",
        "\n",
        "sns.kdeplot(df['beta'], ax=ax1)\n",
        "sns.kdeplot(df['exponential'], ax=ax1)\n",
        "sns.kdeplot(df['normal_p'], ax=ax1)\n",
        "sns.kdeplot(df['normal_l'], ax=ax1)\n",
        "sns.kdeplot(df['bimodal'], ax=ax1);\n",
        "sns.kdeplot(df['new_column'], ax=ax1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH5cHgrZn5NY"
      },
      "source": [
        "Hur gick det?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2e795d7547fd02aec36fc682cc651b507dd677d1",
        "id": "kHHPBSy0n5NY"
      },
      "source": [
        "Testar några olika sätt att skala dataframes.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "98aa148dba37013510ec222678140461deab99b5",
        "id": "BZ_Zatq8n5NY"
      },
      "source": [
        "### MinMaxScaler\n",
        "\n",
        "MinMaxScaler subtraherar varje värde i en kolumn med medelvärdet av den kolumnen och dividerar sedan med antalet värden. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8d53fbc635fdbe9c31c5a02368fdacfea44074ee",
        "id": "gt9M9tMVn5NZ"
      },
      "source": [
        "mm_scaler = preprocessing.MinMaxScaler()\n",
        "df_mm = mm_scaler.fit_transform(df)\n",
        "\n",
        "df_mm = pd.DataFrame(df_mm, columns=col_names)\n",
        "\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
        "ax1.set_title('After MinMaxScaler')\n",
        "\n",
        "sns.kdeplot(df_mm['beta'], ax=ax1)\n",
        "sns.kdeplot(df_mm['exponential'], ax=ax1)\n",
        "sns.kdeplot(df_mm['normal_p'], ax=ax1)\n",
        "sns.kdeplot(df_mm['normal_l'], ax=ax1)\n",
        "sns.kdeplot(df_mm['bimodal'], ax=ax1)\n",
        "sns.kdeplot(df_mm['new_column'], ax=ax1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5ab1940ed342ab438bd8e437a09a482e56e17f39",
        "id": "lddEPpYTn5NZ"
      },
      "source": [
        "Vad har hänt med värdena?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "df57c21b0769fbde43c7597aa9ca5cbf81bcaf71",
        "id": "KJuynwudn5NZ"
      },
      "source": [
        "df_mm['beta'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0814a537a7be26fe065aa5f2ae9efa38d9741bf2",
        "id": "xZJ45uIYn5NZ"
      },
      "source": [
        "df_mm['beta'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "11ef371c86a091c06701184504d0da556baae434",
        "id": "P44JIbNBn5Na"
      },
      "source": [
        "Vi jämför med min och maxvärde för varje kolumn innan vi normaliserade vår dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c8a2e55bad1eb2911e2a2fae29bc2ba9e4f0066a",
        "id": "eM1WPUARn5Na"
      },
      "source": [
        "mins = [df[col].min() for col in df.columns]\n",
        "mins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3080138c4cbf61f372184d52406d5388defde718",
        "id": "dF2cUljMn5Na"
      },
      "source": [
        "maxs = [df[col].max() for col in df.columns]\n",
        "maxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "67d547c34122a3f2659a7320bd98881e0b6b9edd",
        "id": "0NC8KALyn5Na"
      },
      "source": [
        "Kollar min och max för alla kolumner efter skalning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a67a1650ea6c4d83d35f389570b566a8da9630b4",
        "id": "Rz4Qkdo8n5Na"
      },
      "source": [
        "mins = [df_mm[col].min() for col in df_mm.columns]\n",
        "mins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8a560f67852f8843f4b5215c2cee5f6be7ed9f0f",
        "id": "rA677ITCn5Nb"
      },
      "source": [
        "maxs = [df_mm[col].max() for col in df_mm.columns]\n",
        "maxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "31bb92f2bbccd3a4cec450bbb26d96cc83e08489",
        "id": "nt45zaH9n5Nb"
      },
      "source": [
        "Vad har hänt?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e89e7885204f606c89e5d4557876bba7991c5fc7",
        "id": "441XS9EHn5Nb"
      },
      "source": [
        "### RobustScaler\n",
        "\n",
        "RobustScaler subtraherar med medianen för kolumnen och dividerar med kvartilavståndet (skillnaden mellan största 25% och minsta 25%) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f2b82a1ca80ec44d0e25d55ef2e7e5ff440c87ec",
        "id": "cHrTxtQxn5Nb"
      },
      "source": [
        "r_scaler = preprocessing.RobustScaler()\n",
        "df_r = r_scaler.fit_transform(df)\n",
        "\n",
        "df_r = pd.DataFrame(df_r, columns=col_names)\n",
        "\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
        "ax1.set_title('After RobustScaler')\n",
        "\n",
        "sns.kdeplot(df_r['beta'], ax=ax1)\n",
        "sns.kdeplot(df_r['exponential'], ax=ax1)\n",
        "sns.kdeplot(df_r['normal_p'], ax=ax1)\n",
        "sns.kdeplot(df_r['normal_l'], ax=ax1)\n",
        "sns.kdeplot(df_r['bimodal'], ax=ax1)\n",
        "sns.kdeplot(df_r['new_column'], ax=ax1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "dcc077aec1581f20498dc05d1a22e5be78c92535",
        "id": "qDwWTOXen5Nb"
      },
      "source": [
        "Vi kollar igen min och max efteråt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8d4030ddd4b584432da924289723c26e697eb5cd",
        "id": "sEjDBrVDn5Nc"
      },
      "source": [
        "mins = [df_r[col].min() for col in df_r.columns]\n",
        "mins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "523cc16efeacd12e3c637f6def1664796e7daf99",
        "id": "CaINaaRUn5Nc"
      },
      "source": [
        "maxs = [df_r[col].max() for col in df_r.columns]\n",
        "maxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "4dbf7394dfea6178f104f7dcc2f4ccccc4f0ee0a",
        "id": "92oOTby7n5Nc"
      },
      "source": [
        "Vad har hänt?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3b5146b80a9ae1c1d098543c9c11cfad608b0ba9",
        "id": "eY9nowXIn5Nc"
      },
      "source": [
        "### StandardScaler\n",
        "\n",
        "StandardScaler skalar varje kolumn till att ha 0 som medelvärde och standardavvikelsen 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "08609ebc1ed00191c609393550c3ff669f61de67",
        "id": "yP6ctrnSn5Nc"
      },
      "source": [
        "s_scaler = preprocessing.StandardScaler()\n",
        "df_s = s_scaler.fit_transform(df)\n",
        "\n",
        "df_s = pd.DataFrame(df_s, columns=col_names)\n",
        "\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
        "ax1.set_title('After StandardScaler')\n",
        "\n",
        "sns.kdeplot(df_s['beta'], ax=ax1)\n",
        "sns.kdeplot(df_s['exponential'], ax=ax1)\n",
        "sns.kdeplot(df_s['normal_p'], ax=ax1)\n",
        "sns.kdeplot(df_s['normal_l'], ax=ax1)\n",
        "sns.kdeplot(df_s['bimodal'], ax=ax1)\n",
        "sns.kdeplot(df_s['new_column'], ax=ax1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "044277ab27467f23402f566828cc893d262a061c",
        "id": "5YPO0qJnn5Nd"
      },
      "source": [
        "Vi kontrollerar min och max återigen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "297211c50cf6edd0bf4f455e31c632855ea7755e",
        "id": "jKtFxuaCn5Nd"
      },
      "source": [
        "mins = [df_s[col].min() for col in df_s.columns]\n",
        "mins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3b16a6d312335e82671f2f763d97e1c83473717c",
        "id": "Q_mRh0a9n5Nd"
      },
      "source": [
        "maxs = [df_s[col].max() for col in df_s.columns]\n",
        "maxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d3c4868647d4505f7bf735f36dae13d40be7d904",
        "id": "78RDEUadn5Nd"
      },
      "source": [
        "Vad har hänt? I jämförelse med de två innan?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "41d47dbcd963627eab1323d986478ddc5a0c93a4",
        "id": "020Zhvnen5Nd"
      },
      "source": [
        "# Normalizer\n",
        "\n",
        "Normaliser transformerar rader istället för kolumner genom att (default) beräkna den Euclidiska normen som är roten ur summan av roten ur samtliga värden. Kallas för l2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7acbee8b8b745a8c347c055540f1f4f4bef588f7",
        "id": "SuHSDcdGn5Nd"
      },
      "source": [
        "n_scaler = preprocessing.Normalizer()\n",
        "df_n = n_scaler.fit_transform(df)\n",
        "\n",
        "df_n = pd.DataFrame(df_n, columns=col_names)\n",
        "\n",
        "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
        "ax1.set_title('After Normalizer')\n",
        "\n",
        "sns.kdeplot(df_n['beta'], ax=ax1)\n",
        "sns.kdeplot(df_n['exponential'], ax=ax1)\n",
        "sns.kdeplot(df_n['normal_p'], ax=ax1)\n",
        "sns.kdeplot(df_n['normal_l'], ax=ax1)\n",
        "sns.kdeplot(df_n['bimodal'], ax=ax1)\n",
        "sns.kdeplot(df_n['new_column'], ax=ax1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7ba477a3a86798f7ce9f0df1cbb218a7fe227173",
        "id": "eynCeXpHn5Ne"
      },
      "source": [
        "Min och max efter skalning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ffde297a55fd6f5f12d275f77dc6bd1a9f6693a3",
        "id": "gyPstJGZn5Ne"
      },
      "source": [
        "mins = [df_n[col].min() for col in df_n.columns]\n",
        "mins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ca22359fca795384a8c169832ac151e7ab6cf46a",
        "id": "8MJEEChfn5Ne"
      },
      "source": [
        "maxs = [df_n[col].max() for col in df_n.columns]\n",
        "maxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "900bd9d48b818fe447d220897fd785439701b09d",
        "id": "OL_0k_mhn5Ne"
      },
      "source": [
        "Vad har hänt?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "501a3d0671b293f8bcd0937aa60df767e0f2c74a",
        "id": "-8Vkh8Z4n5Ne"
      },
      "source": [
        "Nu tar vi en titt på alla olika sätt att skala tillsammans, dock skippar vi normalizern då det är väldigt ovanligt att man vill skala om rader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "798ae56438449253b271a4c9301976fdc65da5e6",
        "id": "As15JphQn5Nf"
      },
      "source": [
        "### Kombinerad plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f02ff366d3cb22eff31266ce0a09ce7801c8384f",
        "id": "cvn85n2dn5Nf"
      },
      "source": [
        "#Själva figuren\n",
        "fig, (ax0, ax1, ax2, ax3) = plt.subplots(ncols=4, figsize=(20, 8))\n",
        "\n",
        "\n",
        "ax0.set_title('Original Distributions')\n",
        "\n",
        "sns.kdeplot(df['beta'], ax=ax0)\n",
        "sns.kdeplot(df['exponential'], ax=ax0)\n",
        "sns.kdeplot(df['normal_p'], ax=ax0)\n",
        "sns.kdeplot(df['normal_l'], ax=ax0)\n",
        "sns.kdeplot(df['bimodal'], ax=ax0)\n",
        "sns.kdeplot(df['new_column'], ax=ax0);\n",
        "\n",
        "\n",
        "ax1.set_title('After MinMaxScaler')\n",
        "\n",
        "sns.kdeplot(df_mm['beta'], ax=ax1)\n",
        "sns.kdeplot(df_mm['exponential'], ax=ax1)\n",
        "sns.kdeplot(df_mm['normal_p'], ax=ax1)\n",
        "sns.kdeplot(df_mm['normal_l'], ax=ax1)\n",
        "sns.kdeplot(df_mm['bimodal'], ax=ax1)\n",
        "sns.kdeplot(df_mm['new_column'], ax=ax1);\n",
        "\n",
        "\n",
        "ax2.set_title('After RobustScaler')\n",
        "\n",
        "sns.kdeplot(df_r['beta'], ax=ax2)\n",
        "sns.kdeplot(df_r['exponential'], ax=ax2)\n",
        "sns.kdeplot(df_r['normal_p'], ax=ax2)\n",
        "sns.kdeplot(df_r['normal_l'], ax=ax2)\n",
        "sns.kdeplot(df_r['bimodal'], ax=ax2)\n",
        "sns.kdeplot(df_r['new_column'], ax=ax2);\n",
        "\n",
        "\n",
        "ax3.set_title('After StandardScaler')\n",
        "\n",
        "sns.kdeplot(df_s['beta'], ax=ax3)\n",
        "sns.kdeplot(df_s['exponential'], ax=ax3)\n",
        "sns.kdeplot(df_s['normal_p'], ax=ax3)\n",
        "sns.kdeplot(df_s['normal_l'], ax=ax3)\n",
        "sns.kdeplot(df_s['bimodal'], ax=ax3)\n",
        "sns.kdeplot(df_s['new_column'], ax=ax3);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8bddab8169d46325087fb8ebb7735147e53ab3b2",
        "id": "Lj-5cfkNn5Nf"
      },
      "source": [
        "Efter samtliga transformationer är värdena på en mer lika skala. MinMax hade varit att föredra här eftersom den ger minst förskjutning av värdena i förhållande till varandra. Det är samma avstånd som i originalet, de andra två skalningsmetoderna ändrar avstånden mellan värdena vilket kommer påverka modellens korrekthet. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFi7J6kIn5Ng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}